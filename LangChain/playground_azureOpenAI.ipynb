{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "# _ = load_dotenv(find_dotenv(),verbose=True) # read local .env file\n",
    "_ = load_dotenv(os.getcwd(),verbose=True) # read local .env file\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "OPENAI_API_BASE = os.getenv(\"OPENAI_API_BASE\")\n",
    "OPENAI_API_TYPE= os.getenv(\"OPENAI_API_TYPE\")\n",
    "OPENAI_API_VERSION = os.getenv(\"OPENAI_API_VERSION\")\n",
    "MODEL = os.getenv(\"OPENAI_DEPLOYMENT_ID\")\n",
    "# EMBEDDINGS_ENGINE = os.getenv(\"EMBEDDING_DEPLOYED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to disable SSL verification that causes problem from my laptop\n",
    "import contextlib2\n",
    "import warnings\n",
    "import requests\n",
    "from urllib3.exceptions import InsecureRequestWarning\n",
    "# Use a context manager for disabling SSL verification with 3rd party modules\n",
    "old_merge_environment_settings = requests.Session.merge_environment_settings\n",
    "\n",
    "@contextlib2.contextmanager\n",
    "def no_ssl_verification():\n",
    "    opened_adapters = set()\n",
    "\n",
    "    def merge_environment_settings(self, url, proxies, stream, verify, cert):\n",
    "        # Verification happens only once per connection so we need to close\n",
    "        # all the opened adapters once we're done. Otherwise, the effects of\n",
    "        # verify=False persist beyond the end of this context manager.\n",
    "        opened_adapters.add(self.get_adapter(url))\n",
    "\n",
    "        settings = old_merge_environment_settings(\n",
    "            self, url, proxies, stream, verify, cert)\n",
    "        settings['verify'] = False\n",
    "\n",
    "        return settings\n",
    "\n",
    "    requests.Session.merge_environment_settings = merge_environment_settings\n",
    "\n",
    "    try:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter('ignore', InsecureRequestWarning)\n",
    "            yield\n",
    "    finally:\n",
    "        requests.Session.merge_environment_settings = old_merge_environment_settings\n",
    "\n",
    "        for adapter in opened_adapters:\n",
    "            try:\n",
    "                adapter.close()\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Play!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "irina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain import PromptTemplate, OpenAI, LLMChain\n",
    "# from textwrap import dedent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "OPENAI_API_BASE = os.getenv(\"OPENAI_API_BASE\")\n",
    "OPENAI_API_TYPE= os.getenv(\"OPENAI_API_TYPE\")\n",
    "OPENAI_API_VERSION = os.getenv(\"OPENAI_API_VERSION\")\n",
    "MODEL = os.getenv(\"OPENAI_DEPLOYMENT_ID\")\n",
    "# EMBEDDINGS_ENGINE = os.getenv(\"EMBEDDING_DEPLOYED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What is the best name to describe \\\n",
    "a company that makes {product}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Github_Projects\\Experiments\\CondaEnv\\env\\Lib\\site-packages\\langchain\\utils\\utils.py:155: UserWarning: WARNING! engine is not default parameter.\n",
      "                engine was transferred to model_kwargs.\n",
      "                Please confirm that engine is what you intended.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'?\\n\\nWhat is the best name to describe a company that makes ice cream? 2 What is a good name for an ice cream shop?\\n\\nWhat is a good name for an ice cream shop? 3 What is a good name for a dessert business?\\n\\nWhat is a good name for a dessert business? 4 What is a good name for a bakery?\\n\\nWhat is a good name for a bakery? 5 What is the most popular ice cream brand?\\n\\nWhat is the most popular ice cream brand? 6 What is the most popular ice cream flavor?\\n\\nWhat is the most popular ice cream flavor? 7 What is the best ice cream shop?\\n\\nWhat is the best ice cream shop? 8 What is a catchy business name?\\n\\nWhat is a catchy business name? 9 What is a cute business name?\\n\\nWhat is a cute business name? 10 What is a unique name for a business?\\n\\nWhat is a unique name for a business? 11 What are some cute bakery names?\\n\\nWhat are some cute bakery names? 12 What are some bakery names?\\n\\nWhat are some bakery names? 13 What are some bakery names that arenâ€™t taken?\\n\\nWhat is the best name to describe a company that makes ice cream?\\n\\nHere are some of the best ice cream company'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = OpenAI(temperature=0.0,\n",
    "                openai_api_base=OPENAI_API_BASE,\n",
    "                openai_api_key=OPENAI_API_KEY,\n",
    "                engine = MODEL)\n",
    "\n",
    "chain = LLMChain(llm=chat, prompt=PromptTemplate.from_template(prompt))\n",
    "\n",
    "with no_ssl_verification():\n",
    "    response = chain.predict(product = 'ice cream')\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! engine is not default parameter.\n",
      "                    engine was transferred to model_kwargs.\n",
      "                    Please confirm that engine is what you intended.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(temperature=0.9,\n",
    "                openai_api_base=OPENAI_API_BASE,\n",
    "                openai_api_key=OPENAI_API_KEY,\n",
    "                engine = MODEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain2 = LLMChain(llm=llm, prompt=ChatPromptTemplate.from_template(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Scoops & Smiles'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with no_ssl_verification():\n",
    "    response2 = chain2.predict(product = 'ice cream')\n",
    "response2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
