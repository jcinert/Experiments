{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Tree of Thoughts (ToT)\n",
    "## Manual approach (via prompts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv(),verbose=True) # read local .env file\n",
    "\n",
    "#  for the langchain\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "OPENAI_API_BASE = os.getenv(\"OPENAI_API_BASE\")\n",
    "OPENAI_API_TYPE= os.getenv(\"OPENAI_API_TYPE\")\n",
    "OPENAI_API_VERSION = os.getenv(\"OPENAI_API_VERSION\")\n",
    "OPENAI_DEPLOYMENT_ID = os.getenv(\"OPENAI_DEPLOYMENT_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "# from langchain.llms import AzureOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to disable SSL verification that causes problem from my laptop\n",
    "from ssl_workaround import no_ssl_verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! engine is not default parameter.\n",
      "                    engine was transferred to model_kwargs.\n",
      "                    Please confirm that engine is what you intended.\n",
      "WARNING! engine is not default parameter.\n",
      "                    engine was transferred to model_kwargs.\n",
      "                    Please confirm that engine is what you intended.\n",
      "WARNING! engine is not default parameter.\n",
      "                    engine was transferred to model_kwargs.\n",
      "                    Please confirm that engine is what you intended.\n",
      "WARNING! engine is not default parameter.\n",
      "                    engine was transferred to model_kwargs.\n",
      "                    Please confirm that engine is what you intended.\n"
     ]
    }
   ],
   "source": [
    "template =\"\"\"\n",
    "Step1 :\n",
    " \n",
    "I have a problem related to {input}. Could you brainstorm three distinct solutions? Please consider a variety of factors such as {perfect_factors}\n",
    "A:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"input\",\"perfect_factors\"],\n",
    "    template = template                      \n",
    ")\n",
    "\n",
    "chain1 = LLMChain(\n",
    "    llm=ChatOpenAI(\n",
    "        temperature=0, \n",
    "        openai_api_base=OPENAI_API_BASE,\n",
    "        openai_api_key=OPENAI_API_KEY,\n",
    "        engine = OPENAI_DEPLOYMENT_ID),\n",
    "    prompt=prompt,\n",
    "    output_key=\"solutions\"\n",
    ")\n",
    "\n",
    "template =\"\"\"\n",
    "Step 2:\n",
    "\n",
    "For each of the three proposed solutions, evaluate their potential. Consider their pros and cons, initial effort needed, implementation difficulty, potential challenges, and the expected outcomes. Assign a probability of success and a confidence level to each option based on these factors\n",
    "\n",
    "{solutions}\n",
    "\n",
    "A:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"solutions\"],\n",
    "    template = template                      \n",
    ")\n",
    "\n",
    "chain2 = LLMChain(\n",
    "    llm=ChatOpenAI(\n",
    "        temperature=0, \n",
    "        openai_api_base=OPENAI_API_BASE,\n",
    "        openai_api_key=OPENAI_API_KEY,\n",
    "        engine = OPENAI_DEPLOYMENT_ID),\n",
    "    prompt=prompt,\n",
    "    output_key=\"review\"\n",
    ")\n",
    "\n",
    "template =\"\"\"\n",
    "Step 3:\n",
    "\n",
    "For each solution, deepen the thought process. Generate potential scenarios, strategies for implementation, any necessary partnerships or resources, and how potential obstacles might be overcome. Also, consider any potential unexpected outcomes and how they might be handled.\n",
    "\n",
    "{review}\n",
    "\n",
    "A:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"review\"],\n",
    "    template = template                      \n",
    ")\n",
    "\n",
    "chain3 = LLMChain(\n",
    "    llm=ChatOpenAI(\n",
    "        temperature=0,\n",
    "        openai_api_base=OPENAI_API_BASE,\n",
    "        openai_api_key=OPENAI_API_KEY,\n",
    "        engine = OPENAI_DEPLOYMENT_ID),\n",
    "    prompt=prompt,\n",
    "    output_key=\"deepen_thought_process\"\n",
    ")\n",
    "\n",
    "template =\"\"\"\n",
    "Step 4:\n",
    "\n",
    "Based on the evaluations and scenarios, rank the solutions in order of promise. Provide a justification for each ranking and offer any final thoughts or considerations for each solution\n",
    "{deepen_thought_process}\n",
    "\n",
    "A:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"deepen_thought_process\"],\n",
    "    template = template                      \n",
    ")\n",
    "\n",
    "chain4 = LLMChain(\n",
    "    llm=ChatOpenAI(\n",
    "        temperature=0, \n",
    "        openai_api_base=OPENAI_API_BASE,\n",
    "        openai_api_key=OPENAI_API_KEY,\n",
    "        engine = OPENAI_DEPLOYMENT_ID),\n",
    "    prompt=prompt,\n",
    "    output_key=\"ranked_solutions\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Develop sustainable and self-sufficient habitats on Mars: One solution could be to focus on developing habitats that are capable of sustaining human life on Mars without the need for regular resupply from Earth. This could involve using local resources such as water and minerals to create food, oxygen, and other necessities for survival.\n",
      "\n",
      "2. Establish a regular supply chain: Another solution could be to establish a regular supply chain between Earth and Mars, using advanced spacecraft and logistics systems to transport essential supplies and equipment to the planet. This could involve developing new technologies such as reusable rockets and advanced robotics to make the process more efficient and cost-effective.\n",
      "\n",
      "3. Develop a hybrid approach: A third solution could be to combine the above two approaches, by developing sustainable habitats on Mars while also establishing a regular supply chain from Earth. This could involve using the supply chain to transport critical supplies and equipment to the planet, while also focusing on developing local resources and technologies to reduce the need for resupply over time.\n"
     ]
    }
   ],
   "source": [
    "chain1\n",
    "with no_ssl_verification():\n",
    "    response = chain1.predict(input = \"human colonization of Mars\",\n",
    "                            perfect_factors = \"The distance between Earth and Mars is very large, making regular resupply difficult\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "import langchain\n",
    "langchain.debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "overall_chain = SequentialChain(\n",
    "    chains=[chain1, chain2, chain3, chain4],\n",
    "    input_variables=[\"input\", \"perfect_factors\"],\n",
    "    output_variables=[\"ranked_solutions\"],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "with no_ssl_verification():\n",
    "    solution = overall_chain({\"input\":\"human colonization of Mars\", \"perfect_factors\":\"The distance between Earth and Mars is very large, making regular resupply difficult\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'human colonization of Mars', 'perfect_factors': 'The distance between Earth and Mars is very large, making regular resupply difficult', 'ranked_solutions': 'Based on the evaluations and scenarios, the solutions can be ranked in the following order of promise:\\n\\n1. Developing a hybrid approach\\n2. Establishing a regular supply chain\\n3. Developing sustainable and self-sufficient habitats on Mars\\n\\nThe hybrid approach is ranked as the most promising solution because it combines the benefits of both sustainable habitats and a regular supply chain. This approach allows for long-term habitation on Mars while also ensuring a steady supply of essential resources and equipment. The potential obstacles of coordinating and integrating the two approaches can be overcome with partnerships and research and development investments. The unexpected outcomes of this approach could lead to new technologies and methods for integrating sustainable habitats and space transportation that could have applications beyond Mars missions.\\n\\nThe second solution of establishing a regular supply chain is ranked second because it addresses the immediate need for essential resources and equipment on Mars. The potential scenarios of reusable rockets and new propulsion technologies can make space transportation more efficient. However, the high cost of developing and maintaining the supply chain and the technical challenges of transporting supplies and equipment over long distances in space are potential obstacles. The unexpected outcomes of this solution could lead to the development of new technologies or methods for space transportation that could have applications beyond Mars missions.\\n\\nThe third solution of developing sustainable and self-sufficient habitats on Mars is ranked last because it only addresses the long-term habitation needs on Mars. The potential scenarios of underground habitats or 3D printing technology can be used to construct habitats using local resources. However, the difficulty of accessing and utilizing local resources on Mars and the high cost and technical challenges of developing sustainable habitats in an extreme environment are potential obstacles. The unexpected outcomes of this solution could lead to the discovery of new technologies or resources that could be used to further improve sustainability on Mars. \\n\\nOverall, it is important to consider the potential obstacles and unexpected outcomes of each solution before implementing them. Partnerships with private companies and international space agencies can also be crucial for sharing resources and expertise.'}\n"
     ]
    }
   ],
   "source": [
    "print(solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential chain - another one for movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! engine is not default parameter.\n",
      "                    engine was transferred to model_kwargs.\n",
      "                    Please confirm that engine is what you intended.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(\n",
    "        temperature=0, \n",
    "        openai_api_base=OPENAI_API_BASE,\n",
    "        openai_api_key=OPENAI_API_KEY,\n",
    "        engine = OPENAI_DEPLOYMENT_ID)\n",
    "\n",
    "# prompt template 1: translate to english\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Translate the following review to english:\"\n",
    "    \"\\n\\n{Review}\"\n",
    ")\n",
    "# chain 1: input= Review and output= English_Review\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt, \n",
    "                     output_key=\"English_Review\"\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Can you summarize the following review in 1 sentence:\"\n",
    "    \"\\n\\n{English_Review}\"\n",
    ")\n",
    "# chain 2: input= English_Review and output= summary\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt, \n",
    "                     output_key=\"summary\"\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 3: translate to english\n",
    "third_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What language is the following review:\\n\\n{Review}\"\n",
    ")\n",
    "# chain 3: input= Review and output= language\n",
    "chain_three = LLMChain(llm=llm, prompt=third_prompt,\n",
    "                       output_key=\"language\"\n",
    "                      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 4: follow up message\n",
    "fourth_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a follow up response to the following \"\n",
    "    \"summary in the specified language:\"\n",
    "    \"\\n\\nSummary: {summary}\\n\\nLanguage: {language}\"\n",
    ")\n",
    "# chain 4: input= summary, language and output= followup_message\n",
    "chain_four = LLMChain(llm=llm, prompt=fourth_prompt,\n",
    "                      output_key=\"followup_message\"\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall_chain: input= Review \n",
    "# and output= English_Review,summary, followup_message\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_one, chain_two, chain_three, chain_four],\n",
    "    input_variables=[\"Review\"],\n",
    "    output_variables=[\"English_Review\", \"summary\",\"followup_message\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "with no_ssl_verification():\n",
    "    outcome = overall_chain(\"tohle je kratke review. film je super.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Review': 'tohle je kratke review. film je super.',\n",
       " 'English_Review': 'This is a short review. The movie is great.',\n",
       " 'summary': 'The movie is great.',\n",
       " 'followup_message': 'Shrnutí: Film je skvělý.\\n\\nReakce: To je skvělé! Mám rád, když se lidem líbí filmy. Můžeš mi říct více o tom, co se ti na filmu líbilo? Byla to dobrá zábava nebo měl film hlubší poselství? Rád bych slyšel více podrobností o tom, co dělá tento film tak skvělým.'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcome"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
