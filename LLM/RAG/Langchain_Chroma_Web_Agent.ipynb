{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG with Agents\n",
    "adopted from: https://python.langchain.com/docs/use_cases/question_answering/conversational_retrieval_agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain.chat_models import  AzureChatOpenAI\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.embeddings import AzureOpenAIEmbeddings\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "# from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.schema.runnable  import RunnablePassthrough\n",
    "from ssl_workaround import no_ssl_verification\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Openai secrets loaded, models: gpt-35-turbo, text-embedding-ada-002\n"
     ]
    }
   ],
   "source": [
    "def init():\n",
    "    _ = load_dotenv(find_dotenv()) # read local .env file\n",
    "    openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "    openai.api_base = os.environ['OPENAI_API_BASE']\n",
    "    openai.api_type= os.environ['OPENAI_API_TYPE']\n",
    "    openai.api_version = os.environ['OPENAI_API_VERSION']\n",
    "    print(f'Openai secrets loaded, models: {os.environ[\"OPENAI_DEPLOYMENT_ID_LLM\"]}, {os.environ[\"OPENAI_DEPLOYMENT_ID_EMBED\"]}')\n",
    "init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load from Web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads URL content into a document - one document per URL\n",
    "# only extracts the content of the post-content, post-title, and post-header classes\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs={\n",
    "        \"parse_only\": bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    },\n",
    ")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuber of docs loaded: 1\n",
      "First doc lenght: 42824\n",
      "Sample: \n",
      "\n",
      "      LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In\n"
     ]
    }
   ],
   "source": [
    "# test doc loading\n",
    "print(f'Nuber of docs loaded: {len(docs)}')\n",
    "print(f'First doc lenght: {len(docs[0].page_content)}')\n",
    "print(f'Sample: {docs[0].page_content[:500]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Split\n",
    "- LLM struggle to find info in very long context, we should split it in reasonable long documents\n",
    "- its good to have overlap between spit documents in order not to loose context from ending / begginging chunk parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents created: 66\n",
      "First document length: 969\n",
      "Metadata sample: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 8}\n"
     ]
    }
   ],
   "source": [
    "# test splitter\n",
    "print(f'Number of documents created: {len(all_splits)}')\n",
    "print(f'First document length: {len(all_splits[0].page_content)}')\n",
    "print(f'Metadata sample: {all_splits[0].metadata}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = './data/test_vectorstore_llm_azureemb/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Github_Projects\\Experiments\\CondaEnv\\env\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.azure_openai.AzureOpenAIEmbeddings` was deprecated in langchain-community 0.1.0 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import AzureOpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "embedding=AzureOpenAIEmbeddings(azure_deployment=os.environ['OPENAI_DEPLOYMENT_ID_EMBED'],max_retries=10, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53f8baae72be4ecf8481ee1b72e8b6a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_community.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2023-09-01-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain_community.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2023-09-01-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain_community.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2023-09-01-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain_community.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 8.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2023-09-01-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 48 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain_community.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 16.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2023-09-01-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain_community.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 20.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2023-09-01-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 23 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain_community.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 20.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2023-09-01-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain_community.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2023-09-01-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain_community.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2023-09-01-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain_community.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2023-09-01-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain_community.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 8.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2023-09-01-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 48 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain_community.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 16.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2023-09-01-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain_community.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 20.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2023-09-01-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 24 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain_community.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 20.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2023-09-01-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain_community.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2023-09-01-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain_community.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2023-09-01-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain_community.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2023-09-01-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain_community.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 8.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2023-09-01-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 48 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain_community.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 16.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2023-09-01-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain_community.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 20.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2023-09-01-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 23 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain_community.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 20.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2023-09-01-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain_community.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2023-09-01-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain_community.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2023-09-01-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain_community.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2023-09-01-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain_community.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 8.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2023-09-01-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 48 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain_community.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 16.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2023-09-01-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain_community.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 20.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2023-09-01-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 24 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain_community.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 20.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2023-09-01-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n"
     ]
    }
   ],
   "source": [
    "# OPTION 1: create vectorstore from scratch - needed first time\n",
    "vectorstore = Chroma.from_documents(\n",
    "                                documents=all_splits, \n",
    "                                embedding=embedding, \n",
    "                                persist_directory=persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION 2: load vectorstore from disk - faster\n",
    "vectorstore = Chroma(\n",
    "            persist_directory=persist_directory, \n",
    "            embedding_function=embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retriever tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fd45da0cf9e4f7d9d48bdd50339d6dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Number of documents retrieved: 3\n",
      "---Doc 0 length: 644\n",
      "---Doc 0: Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "---Doc 1 length: 606\n",
      "---Doc 1: Fig. 1. Overview of a LLM-powered autonomous agent system.\n",
      "Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n"
     ]
    }
   ],
   "source": [
    "# retriever test\n",
    "retrieved_docs = retriever.get_relevant_documents(\n",
    "    \"What are the approaches to Task Decomposition?\"\n",
    ")\n",
    "print(f'---Number of documents retrieved: {len(retrieved_docs)}')\n",
    "print(f'---Doc 0 length: {len(retrieved_docs[0].page_content)}')\n",
    "print(f'---Doc 0: {retrieved_docs[0].page_content}')\n",
    "print(f'---Doc 1 length: {len(retrieved_docs[1].page_content)}')\n",
    "print(f'---Doc 1: {retrieved_docs[1].page_content}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create agent\n",
    "adopted from: https://github.com/pinecone-io/examples/blob/master/learn/generation/langchain/handbook/08-langchain-retrieval-agent.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Github_Projects\\Experiments\\CondaEnv\\env\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.azure_openai.AzureChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import AzureChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "llm = AzureChatOpenAI(azure_deployment=os.environ['OPENAI_DEPLOYMENT_ID_LLM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# conversational memory\n",
    "conversational_memory = ConversationBufferWindowMemory(\n",
    "    memory_key='chat_history',\n",
    "    k=5,\n",
    "    return_messages=True\n",
    ")\n",
    "# retrieval qa chain\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Github_Projects\\Experiments\\CondaEnv\\env\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "586204a429a74dcd8b7f9f9a2a7d32a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'The Reflection framework can be used in LLM apps to help the autonomous agent improve iteratively by refining past action decisions and correcting previous mistakes. The heuristic function determines when the trajectory is inefficient or contains hallucination and should be stopped. Inefficient planning refers to trajectories that take too long without success. Hallucination is defined as encountering a sequence of consecutive identical actions that lead to the same observation in the environment. Self-reflection is created by showing two-shot examples to LLM, and each example is a pair of (failed trajectory, ideal reflection for guiding future changes in the plan). Then reflections are added into the agent’s working memory, up to three, to be used as context for querying LLM.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.run(\"How can the reflextion framework be used in LLM apps?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adding retriever (KB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name='Knowledge Base',\n",
    "        func=qa.run,\n",
    "        description=(\n",
    "            'use this tool when answering general knowledge queries to get '\n",
    "            'more information about LLM apps'\n",
    "        )\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Github_Projects\\Experiments\\CondaEnv\\env\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "\n",
    "agent = initialize_agent(\n",
    "    agent='chat-conversational-react-description',\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    max_iterations=3,\n",
    "    early_stopping_method='generate',\n",
    "    memory=conversational_memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_msg = \"\"\"Assistant is a large language model.\n",
    "\n",
    "Assistant is designed to be able to assist with a wide range of tasks related to LLMs, machine learning and programming , \\\n",
    "from answering simple questions to providing in-depth explanations, example code and links to documentation. \\\n",
    "As a language model, Assistant is able to generate human-like text based on the input it receives, \\\n",
    "allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
    "Assistant can use code spippets and URL links.\n",
    "\n",
    "Assistant is constantly learning and improving, and its capabilities are constantly evolving. \\\n",
    "It is able to process and understand large amounts of text, and can use this knowledge to provide accurate \\\n",
    "and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input \\\n",
    "it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics related to LLMs, machine learning and programming.\n",
    "\n",
    "If the question is related to LLMs, machine learning and programming Assistant has to first use the Knowledge Base. \\\n",
    "\n",
    "If the question is not related to LLMs, machine learning and programming, Assistant has to respond: \\\n",
    "I'm sorry this is not my area of expertise.\n",
    "\n",
    "\"\"\"\n",
    "# If no relevant answer is found in the Knowlege Base, Assistant can use Web Search tool to find an answer on the internet. \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_prompt = agent.agent.create_prompt(\n",
    "    system_message=sys_msg,\n",
    "    tools=tools\n",
    ")\n",
    "\n",
    "agent.agent.llm_chain.prompt = new_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Knowledge Base\",\n",
      "    \"action_input\": \"Tree of Thoughts is not a well-known term in the context of LLM apps. Could you please provide more information or context about what you are referring to so I can better assist you?\"\n",
      "}\u001b[0m"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29af8c0c7d6540198d259feaf1089b71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3mCertainly! Tree of Thoughts is a model proposed by Yao et al. in 2023 that extends the CoT (Compositional Transformers) model by exploring multiple reasoning possibilities at each step. It decomposes a problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote. The purpose of this model is to address the challenges of long-term planning and effective exploration of the solution space, which are still challenging for LLMs.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"Tree of Thoughts is a model proposed by Yao et al. in 2023 to address the challenges of long-term planning and effective exploration of the solution space in LLMs. It extends the CoT model by exploring multiple reasoning possibilities at each step, creating a tree structure. The search process can be BFS or DFS with each state evaluated by a classifier via a prompt or majority vote.\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Tree of Thoughts is a model proposed by Yao et al. in 2023 to address the challenges of long-term planning and effective exploration of the solution space in LLMs. It extends the CoT model by exploring multiple reasoning possibilities at each step, creating a tree structure. The search process can be BFS or DFS with each state evaluated by a classifier via a prompt or majority vote.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"How can Tree of Thoughts be used in LLM apps?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adding a search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install --upgrade --quiet  duckduckgo-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import DuckDuckGoSearchRun, DuckDuckGoSearchResults\n",
    "from langchain_community.utilities import DuckDuckGoSearchAPIWrapper\n",
    "\n",
    "wrapper = DuckDuckGoSearchAPIWrapper(time=\"y\", max_results=3)\n",
    "search = DuckDuckGoSearchResults(api_wrapper=wrapper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[snippet: Unambiguously, Python is the best language for machine learning. It's an interpreted language that is easy to read and understand, as its syntax is relatively similar to spoken languages. Because of this, it is also one of the easiest languages to learn., title: The Best Programming Languages for Machine Learning, link: https://tripleten.com/blog/posts/the-best-programming-languages-for-machine-learning], [snippet: Lower-level languages (like R, C++, or Java) offer greater speed but are harder to learn. Higher-level languages (like JavaScript and Python) are easier to use but slower to execute. Python is a key language for machine learning and data analytics. For speed-to-competence and breadth of application, it's probably the best one for beginners., title: What's the Best Language for Machine Learning? - CareerFoundry, link: https://careerfoundry.com/en/blog/data-analytics/best-machine-learning-languages/], [snippet: Contents 1. Best programming languages for machine learning in 2023 2. 12 best languages for machine learning 2.1 Python - the top machine learning language 2.2 R language 2.3 C# 2.4 C++ 2.5 Julia 2.6 Haskell 2.7 Java 2.8 Scala 2.9 JavaScript 2.10 Go 2.11 Wolfram 2.12 MatLab 3. Machine learning programming FAQ 3.1 What exactly is machine learning?, title: Best Machine Learning Languages in 2023: Choose the Right One, link: https://atlasiko.com/blog/ai/best-language-for-machine-learning/], [snippet: Most Popular Programming Languages & Why They're Useful in Machine Learning - neptune.ai Online forums and data science blogs have plenty of recommendations: learn that language, keep up with that framework, have you looked at that library?, title: Most Popular Programming Languages & Why They're Useful in Machine ..., link: https://neptune.ai/blog/programming-languages-machine-learning]\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test search\n",
    "search.run(\"What is the best programming language for ML?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name='Knowledge Base',\n",
    "        func=qa.run,\n",
    "        description=(\n",
    "            'First tool to use when answering questions about LLM, LLM apps and the LLM frameworks'\n",
    "        )\n",
    "    ),\n",
    "    Tool(\n",
    "        name='Web Search',\n",
    "        func=search.run,\n",
    "        description=(\n",
    "            'Tool to use for generic LLMs, machine learning and programming related questions'\n",
    "        )\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(\n",
    "    agent='chat-conversational-react-description',\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    max_iterations=3,\n",
    "    early_stopping_method='generate',\n",
    "    memory=conversational_memory,\n",
    "    handle_parsing_errors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_msg = \"\"\"Assistant is a large language model.\n",
    "\n",
    "Assistant is designed to be able to assist with a wide range of tasks related to LLMs, machine learning and programming , \\\n",
    "from answering simple questions to providing in-depth explanations, example code and links to documentation. \\\n",
    "As a language model, Assistant is able to generate human-like text based on the input it receives, \\\n",
    "allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
    "Assistant can use code spippets and URL links.\n",
    "\n",
    "Assistant is constantly learning and improving, and its capabilities are constantly evolving. \\\n",
    "It is able to process and understand large amounts of text, and can use this knowledge to provide accurate \\\n",
    "and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input \\\n",
    "it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics related to LLMs, machine learning and programming.\n",
    "\n",
    "If the question is related to LLMs, machine learning and programming Assistant has to first use the Knowledge Base. \\\n",
    "If no relevant answer is found in the Knowlege Base, Assistant can use Web Search tool to find an answer on the internet. \\\n",
    "\n",
    "If the question is not related to LLMs, machine learning and programming, Assistant has to respond: \\\n",
    "I'm sorry this is not my area of expertise.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_prompt = agent.agent.create_prompt(\n",
    "    system_message=sys_msg,\n",
    "    tools=tools\n",
    ")\n",
    "\n",
    "agent.agent.llm_chain.prompt = new_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Knowledge Base\",\n",
      "    \"action_input\": \"How can Tree of Thoughts be used in LLM apps?\"\n",
      "}\u001b[0m"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2193a548bb2846cd8d6deb724c2cd393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3mTree of Thoughts can be used in LLM apps to explore multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote. Task decomposition can be done using LLM with simple prompting, using task-specific instructions, or with human inputs.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"Tree of Thoughts can be used in LLM apps to explore multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS or DFS with each state evaluated by a classifier or majority vote. Task decomposition can be done using LLM with simple prompting, using task-specific instructions, or with human inputs.\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Tree of Thoughts can be used in LLM apps to explore multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS or DFS with each state evaluated by a classifier or majority vote. Task decomposition can be done using LLM with simple prompting, using task-specific instructions, or with human inputs.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"How can Tree of Thoughts be used in LLM apps?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Web Search\",\n",
      "    \"action_input\": \"Best programming language for machine learning\"\n",
      "}\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m[snippet: 1. Python What is Python? Unambiguously, Python is the best language for machine learning. It's an interpreted language that is easy to read and understand, as its syntax is relatively similar to spoken languages. Because of this, it is also one of the easiest languages to learn., title: The Best Programming Languages for Machine Learning, link: https://tripleten.com/blog/posts/the-best-programming-languages-for-machine-learning], [snippet: Lower-level languages (like R, C++, or Java) offer greater speed but are harder to learn. Higher-level languages (like JavaScript and Python) are easier to use but slower to execute. Python is a key language for machine learning and data analytics. For speed-to-competence and breadth of application, it's probably the best one for beginners., title: What's the Best Language for Machine Learning? - CareerFoundry, link: https://careerfoundry.com/en/blog/data-analytics/best-machine-learning-languages/], [snippet: Most Popular Programming Languages & Why They're Useful in Machine Learning - neptune.ai Online forums and data science blogs have plenty of recommendations: learn that language, keep up with that framework, have you looked at that library?, title: Most Popular Programming Languages & Why They're Useful in Machine Learning, link: https://neptune.ai/blog/programming-languages-machine-learning], [snippet: 1. Python Programming Language 2. R Programming Language 3. Java 4. JavaScript 5. Julia 6. LISP 7. C++ Conclusion References Also Read: Kotlin vs Python: What is the Difference? What is Machine Learning? Before we look at individual programming languages, it is worth clearing up some of the terms of machine learning., title: 7 Best Programming Languages for Machine Learning, link: https://www.aiplusinfo.com/blog/7-best-programming-languages-for-machine-learning/]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"Python is widely considered the best programming language for machine learning due to its ease of use and readability. Other popular languages in the field include R, Java, and JavaScript. However, Python's popularity, large community, and extensive libraries make it a great choice for beginners and experts alike.\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Python is widely considered the best programming language for machine learning due to its ease of use and readability. Other popular languages in the field include R, Java, and JavaScript. However, Python's popularity, large community, and extensive libraries make it a great choice for beginners and experts alike.\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"What is the best programming language for ML?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hello world search agent below..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "basic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import DuckDuckGoSearchRun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = DuckDuckGoSearchRun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"August 4, 1961, Honolulu, Hawaii, U.S. (age 62) Title / Office: presidency of the United States of America (2009-2017), United States United States Senate (2005-2008), United States (Show more) Political Affiliation: Democratic Party Awards And Honors: Nobel Prize (2009) Grammy Award (2007) Grammy Award (2005) Life After the Presidency How Tall is Obama? Books and Grammy Hobbies Movies About Obama Quotes 1961-present Who Is Barack Obama? Barack Obama was the 44 th president of the United States... As the head of the government of the United States, the president is arguably the most powerful government official in the world. The president is elected to a four-year term via an electoral college system. Since the Twenty-second Amendment was adopted in 1951, the American presidency has been 2023. 3. Former President Barack Obama, born on Aug. 4, 1961, in Honolulu, Hawaii, made a name for himself during his decades spent in politics starting in 1997 as an Illinois State Senator ... His name was Clifford L. Alexander Jr. and he was the nation's first Black secretary of the Army and an advisor to several Democratic presidents. He was also Alexander's father.\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.run(\"Obama's first name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import DuckDuckGoSearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = DuckDuckGoSearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[snippet: Barack Obama (born August 4, 1961, Honolulu, Hawaii, U.S.) 44th president of the United States (2009-17) and the first African American to hold the office. Before winning the presidency, Obama represented Illinois in the U.S. Senate (2005-08). He was the third African American to be elected to that body since the end of Reconstruction (1877)., title: Barack Obama | Biography, Parents, Education, Presidency, Books ..., link: https://www.britannica.com/biography/Barack-Obama], [snippet: Learn about the life and achievements of Barack Obama, the first Black commander-in-chief of the United States. From his early years in Hawaii and Indonesia to his political career in Illinois and Washington, D.C., discover his family background, education, marriage, hobbies, and legacy., title: Barack Obama: Biography, 44th U.S. President, Politician, link: https://www.biography.com/political-figures/barack-obama], [snippet: Barack Obama is sworn in by Chief Justice John Roberts as the 44th president of the United States on January 20, 2009, in Washington. Obama told a story about America at his first inauguration 15 ..., title: The grim backdrop of Obama's first inauguration - CNN, link: https://www.cnn.com/2024/01/20/politics/obama-inauguration-america-blake-cec/index.html], [snippet: The former president shares his views on Biden's reelection chances, Trump's indictment, the war in Ukraine and other topics in a wide-ranging conversation with CNN. He praises Biden's administration, criticizes Trump's behavior and warns of the dangers of AI., title: Five takeaways from Barack Obama's CNN interview on Biden ... - Yahoo, link: https://www.usatoday.com/story/news/politics/2023/06/23/five-takeaways-from-barack-obama-cnn-interview/70349112007/]\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.run(\"Obama\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "just news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[snippet: There is no credible evidence Obama was arrested. Carlson said he never reported it happened and does not have an account on the platform in question., title: Obama wasn\\'t arrested. Tucker Carlson didn\\'t post a video about it, either | Fact check, link: https://www.msn.com/en-us/news/us/obama-wasnt-arrested-tucker-carlson-didnt-post-a-video-about-it-either-fact-check/ar-BB1hdjnl, date: 2024-01-24T22:58:43+00:00, source: USA Today on MSN.com], [snippet: The former first daughter\\'s short, \"The Heart,\" focuses on a sensitive man racked with guilt when his mother dies after they have an argument., title: Malia Obama at Sundance: A Fledgling Filmmaker Makes Her Debut, link: https://www.nytimes.com/2024/01/26/movies/malia-obama-sundance-film-festival.html, date: 2024-01-26T14:45:00+00:00, source: The New York Times], [snippet: The world is not just about snuggling with housebroken puppies and rainbows out your window and riding unicorns bareback.\\xa0 The real world can be terrifying. Just ask former First Lady Michelle Obama., title: Terrors of the Michelle Obama Prophecy, link: https://www.realclearpolitics.com/2024/01/26/terrors_of_the_michelle_obama_prophecy_616699.html, date: 2024-01-26T00:00:00+00:00, source: RealClearPolitics], [snippet: A Chicago investment firm with ties to Barack Obama has hired former Massachusetts Governor Deval Patrick from Bain Capital as a senior adviser., title: Deval Patrick Leaves Bain for Chicago Investment Firm With Obama Ties, link: https://www.msn.com/en-us/money/companies/chicago-investment-firm-with-obama-ties-hires-deval-patrick/ar-BB1hjJOg, date: 2024-01-26T20:54:45+00:00, source: Bloomberg on MSN.com]'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search = DuckDuckGoSearchResults(backend=\"news\")\n",
    "search.run(\"Obama\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wrapper with more control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import DuckDuckGoSearchAPIWrapper\n",
    "\n",
    "wrapper = DuckDuckGoSearchAPIWrapper(region=\"de-de\", time=\"d\", max_results=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[snippet: Aktuell gibt es Gerüchte, dass die Demokraten deswegen eine andere Kandidatin gegen Donald Trump ins Rennen schicken könnten. Wie das Nachrichtenportal \"oe24.at\" berichtet, wird Michelle Obama derzeit als Biden-Nachfolgerin gehandelt. Die Ehefrau von Ex-Präsident Barack Obama hat eine Kandidatur zwar bislang immer wieder verneint, doch Spekulationen gibt es dennoch immer wieder., title: Joe Biden: US-Präsident abgestürzt! Michelle Obama soll seine ..., link: https://www.news.de/politik/857545585/joe-biden-stuerzt-ab-im-politiker-ranking-keine-zweite-amtzeit-michelle-obama-als-praesidentin-geruechte-um-kandidatur-us-wahl-2024/1/], [snippet: Aber auch in unzähligen Privathäusern hat Rissel TV-Geräte verschwinden lassen, die bei Bedarf wieder hinter Bildern auftauchen, aus der Decke oder aus Schrankelementen herausfahren. Seit zwei Jahren nutzt auch Ex-US-Präsident Barack Obama in seiner Villa im kalifornischen Santa Monica ein TV-Lift-System von Sascha Rissel., title: Auch Barack Obama vertraut auf TV-Lift-System aus Worms - Mannheimer Morgen, link: https://www.mannheimer-morgen.de/kultur_artikel,-kultur-auch-barack-obama-vertraut-auf-tv-lift-system-aus-worms-_arid,2169772.html], [snippet: Martin Greenfield ist Herrenmaßschneider. Er arbeitet im New Yorker Stadtteil Brooklyn. Jeder, der etwas auf sich hält, lässt seine Anzüge bei ihm schneidern. Zu seiner Kundschaft gehören amerikanische Präsidenten und die Großen aus dem Show-Business. Er hat die Anzüge von Bill Clinton und Barack Obama angefertigt. Den ersten ..., title: Dokumentation & Feature · Der Schneider der Präsidenten - ARD Audiothek, link: https://www.ardaudiothek.de/episode/dokumentation-und-feature/der-schneider-der-praesidenten/mdr-kultur/13104109/], [snippet: Obama came to office just as the U.S. economy was sliding into what would be called the Great Recession. But both could point to growth (Obama at 4.6% and Reagan at a rip-roaring 8.6%)., title: What numbers can and can\\'t tell us about a sitting president\\'s odds as ..., link: https://www.npr.org/2024/01/27/1225563900/polls-predictor-election-inflation-jobless-misery-index-approval-rating]'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search = DuckDuckGoSearchResults(api_wrapper=wrapper, source=\"news\")\n",
    "search.run(\"Obama\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
